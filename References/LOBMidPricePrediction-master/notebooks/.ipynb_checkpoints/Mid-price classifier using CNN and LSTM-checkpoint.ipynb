{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras as tfk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get limit order book data \n",
    "orderbook = pd.read_csv('/Users/tanvipotdar/Projects/LOBster/data_tqap/INTC_2015-01-01_2015-01-31_10/INTC_2015-01-02_34200000_57600000_orderbook_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ask_price_1</th>\n",
       "      <th>ask_size_1</th>\n",
       "      <th>bid_price_1</th>\n",
       "      <th>bid_size_1</th>\n",
       "      <th>ask_price_2</th>\n",
       "      <th>ask_size_2</th>\n",
       "      <th>bid_price_2</th>\n",
       "      <th>bid_size_2</th>\n",
       "      <th>ask_price_3</th>\n",
       "      <th>ask_size_3</th>\n",
       "      <th>...</th>\n",
       "      <th>bid_price_8</th>\n",
       "      <th>bid_size_8</th>\n",
       "      <th>ask_price_9</th>\n",
       "      <th>ask_size_9</th>\n",
       "      <th>bid_price_9</th>\n",
       "      <th>bid_size_9</th>\n",
       "      <th>ask_price_10</th>\n",
       "      <th>ask_size_10</th>\n",
       "      <th>bid_price_10</th>\n",
       "      <th>bid_size_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.063739</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.816904</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.885917</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-1.092996</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.063739</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.816904</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.885917</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-1.092996</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.154853</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.816904</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.885917</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-1.092996</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.154853</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437242</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.782372</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.851389</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.154853</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437242</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.782372</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.851389</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.154853</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437242</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.782372</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.851389</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.154853</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437242</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.782372</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.851389</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.154853</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437242</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.782372</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.851389</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>-1.154853</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>-2.053207</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.402727</td>\n",
       "      <td>-0.894391</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.402710</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.747843</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>-1.124482</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>-2.053207</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.402727</td>\n",
       "      <td>-0.894391</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.402710</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.747843</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ask_price_1  ask_size_1  bid_price_1  bid_size_1  ask_price_2  ask_size_2  \\\n",
       "0     0.796834   -0.070811     0.114857   -1.063739     0.831288   -1.895349   \n",
       "1     0.796834   -0.070811     0.114857   -1.063739     0.831288   -1.895349   \n",
       "2     0.796834   -0.070811     0.114857   -1.154853     0.831288   -1.895349   \n",
       "3     0.796834   -0.070811     0.114857   -1.154853     0.831288   -1.895349   \n",
       "4     0.796834   -0.070811     0.114857   -1.154853     0.831288   -1.895349   \n",
       "5     0.796834   -0.070811     0.114857   -1.154853     0.831288   -1.895349   \n",
       "6     0.796834   -0.070811     0.114857   -1.154853     0.831288   -1.895349   \n",
       "7     0.796834   -0.070811     0.114857   -1.154853     0.831288   -1.895349   \n",
       "8     0.796834   -0.070811     0.632554   -1.154853     0.831288   -1.895349   \n",
       "9     0.796834   -0.070811     0.632554   -1.124482     0.831288   -1.895349   \n",
       "\n",
       "   bid_price_2  bid_size_2  ask_price_3  ask_size_3  ...  bid_price_8  \\\n",
       "0     0.011343   -1.984987     0.934676   -1.788479  ...    -0.816904   \n",
       "1     0.011343   -1.984987     0.934676   -1.788479  ...    -0.816904   \n",
       "2     0.011343   -1.984987     0.934676   -1.788479  ...    -0.816904   \n",
       "3     0.011343   -1.984987     0.934676   -1.788479  ...    -0.437242   \n",
       "4     0.011343   -1.984987     0.934676   -1.788479  ...    -0.437242   \n",
       "5     0.011343   -1.984987     0.934676   -1.788479  ...    -0.437242   \n",
       "6     0.011343   -1.984987     0.934676   -1.788479  ...    -0.437242   \n",
       "7     0.011343   -1.984987     0.934676   -1.788479  ...    -0.437242   \n",
       "8     0.149397   -2.053207     0.934676   -1.788479  ...    -0.402727   \n",
       "9     0.149397   -2.053207     0.934676   -1.788479  ...    -0.402727   \n",
       "\n",
       "   bid_size_8  ask_price_9  ask_size_9  bid_price_9  bid_size_9  ask_price_10  \\\n",
       "0   -0.872724     2.450812   -0.888307    -0.885917   -1.164202       2.58852   \n",
       "1   -0.872724     2.450812   -0.888307    -0.885917   -1.164202       2.58852   \n",
       "2   -0.872724     2.450812   -0.888307    -0.885917   -1.164202       2.58852   \n",
       "3   -0.872724     2.450812   -0.888307    -0.782372   -1.164202       2.58852   \n",
       "4   -0.872724     2.450812   -0.888307    -0.782372   -1.164202       2.58852   \n",
       "5   -0.872724     2.450812   -0.888307    -0.782372   -1.164202       2.58852   \n",
       "6   -0.872724     2.450812   -0.888307    -0.782372   -1.164202       2.58852   \n",
       "7   -0.872724     2.450812   -0.888307    -0.782372   -1.164202       2.58852   \n",
       "8   -0.894391     2.450812   -0.888307    -0.402710   -1.164202       2.58852   \n",
       "9   -0.894391     2.450812   -0.888307    -0.402710   -1.164202       2.58852   \n",
       "\n",
       "   ask_size_10  bid_price_10  bid_size_10  \n",
       "0    -0.313841     -1.092996    -1.491542  \n",
       "1    -0.313841     -1.092996    -1.491542  \n",
       "2    -0.313841     -1.092996    -1.491542  \n",
       "3    -0.313841     -0.851389    -1.491542  \n",
       "4    -0.313841     -0.851389    -1.491542  \n",
       "5    -0.313841     -0.851389    -1.491542  \n",
       "6    -0.313841     -0.851389    -1.491542  \n",
       "7    -0.313841     -0.851389    -1.491542  \n",
       "8    -0.313841     -0.747843    -1.491542  \n",
       "9    -0.313841     -0.747843    -1.491542  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalise the data\n",
    "from scipy.stats import zscore\n",
    "normalised_data = orderbook.apply(zscore)\n",
    "normalised_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the midprice\n",
    "normalised_data['midprice'] = (normalised_data.ask_price_1+normalised_data.bid_price_1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothed labelling of the midprice/ k is the prediction horizon\n",
    "k = 10\n",
    "# mean of previous k mid-prices\n",
    "normalised_data['m_minus'] = normalised_data['midprice'].rolling(window=k).mean()\n",
    "# mean of next k mid-prices\n",
    "normalised_data['m_plus'] = normalised_data['midprice'][::-1].rolling(window=k).mean()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ask_price_1</th>\n",
       "      <th>ask_size_1</th>\n",
       "      <th>bid_price_1</th>\n",
       "      <th>bid_size_1</th>\n",
       "      <th>ask_price_2</th>\n",
       "      <th>ask_size_2</th>\n",
       "      <th>bid_price_2</th>\n",
       "      <th>bid_size_2</th>\n",
       "      <th>ask_price_3</th>\n",
       "      <th>ask_size_3</th>\n",
       "      <th>...</th>\n",
       "      <th>bid_size_9</th>\n",
       "      <th>ask_price_10</th>\n",
       "      <th>ask_size_10</th>\n",
       "      <th>bid_price_10</th>\n",
       "      <th>bid_size_10</th>\n",
       "      <th>midprice</th>\n",
       "      <th>m_minus</th>\n",
       "      <th>m_plus</th>\n",
       "      <th>change</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>-1.124482</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>-2.053207</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.747843</td>\n",
       "      <td>-1.491542</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.507615</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.407945</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>-1.124482</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>-2.053207</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.747843</td>\n",
       "      <td>-1.491542</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.533500</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.339633</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>-1.124482</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>-2.053207</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.747843</td>\n",
       "      <td>-1.491542</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.559385</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.277643</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>-1.094110</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>-2.053207</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.747843</td>\n",
       "      <td>-1.491542</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.585270</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.221136</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>-1.094110</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>-2.053207</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.197339</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.368176</td>\n",
       "      <td>-1.491542</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.611155</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.169416</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ask_price_1  ask_size_1  bid_price_1  bid_size_1  ask_price_2  ask_size_2  \\\n",
       "9      0.796834   -0.070811     0.632554   -1.124482     0.831288   -1.895349   \n",
       "10     0.796834   -0.070811     0.632554   -1.124482     0.831288   -1.895349   \n",
       "11     0.796834   -0.070811     0.632554   -1.124482     0.831288   -1.895349   \n",
       "12     0.796834   -0.070811     0.632554   -1.094110     0.831288   -1.895349   \n",
       "13     0.796834   -0.070811     0.632554   -1.094110     0.831288   -1.895349   \n",
       "\n",
       "    bid_price_2  bid_size_2  ask_price_3  ask_size_3  ...  bid_size_9  \\\n",
       "9      0.149397   -2.053207     0.934676   -1.788479  ...   -1.164202   \n",
       "10     0.149397   -2.053207     0.934676   -1.788479  ...   -1.164202   \n",
       "11     0.149397   -2.053207     0.934676   -1.788479  ...   -1.164202   \n",
       "12     0.149397   -2.053207     0.934676   -1.788479  ...   -1.164202   \n",
       "13     0.149397   -2.053207     0.934676   -1.788479  ...   -1.197339   \n",
       "\n",
       "    ask_price_10  ask_size_10  bid_price_10  bid_size_10  midprice   m_minus  \\\n",
       "9        2.58852    -0.313841     -0.747843    -1.491542  0.714694  0.507615   \n",
       "10       2.58852    -0.313841     -0.747843    -1.491542  0.714694  0.533500   \n",
       "11       2.58852    -0.313841     -0.747843    -1.491542  0.714694  0.559385   \n",
       "12       2.58852    -0.313841     -0.747843    -1.491542  0.714694  0.585270   \n",
       "13       2.58852    -0.313841     -0.368176    -1.491542  0.714694  0.611155   \n",
       "\n",
       "      m_plus    change  label  \n",
       "9   0.714694  0.407945     up  \n",
       "10  0.714694  0.339633     up  \n",
       "11  0.714694  0.277643     up  \n",
       "12  0.714694  0.221136     up  \n",
       "13  0.714694  0.169416     up  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label the smoothed mid-prices based on a threshold/ alpha is the threshold \n",
    "alpha = 0.0001\n",
    "normalised_data['change'] = (normalised_data.m_plus - normalised_data.m_minus)/normalised_data.m_minus\n",
    "# assign categories up, down, stationary\n",
    "normalised_data['label'] = pd.cut(normalised_data.change, bins=[-np.inf, -alpha, alpha, np.inf], \n",
    "                                  labels=['down', 'stationary', 'up'])\n",
    "# drop all unlabelled values (will be first and last k values as they have no m_minus/m_plus value)\n",
    "normalised_data.dropna(inplace=True)\n",
    "normalised_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input and output train and test data\n",
    "data = normalised_data[:887600]\n",
    "\n",
    "cols = data.columns.to_list()[:40]\n",
    "input_data = data[cols]\n",
    "input_array = input_data.to_numpy().reshape(8876,100,40,1)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "output_data = data.label.to_numpy()[::-100][::-1]\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = output_data.reshape(len(output_data), 1)\n",
    "output_array = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_array, output_array, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['up']\n",
      " ['down']\n",
      " ['down']\n",
      " ...\n",
      " ['stationary']\n",
      " ['stationary']\n",
      " ['stationary']]\n",
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(integer_encoded)\n",
    "print(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_56 (Conv2D)           (None, 100, 20, 16)       48        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 100, 20, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 97, 20, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 94, 20, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 94, 10, 16)        528       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 94, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 91, 10, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 88, 10, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 88, 1, 16)         2576      \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 85, 1, 16)         1040      \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 82, 1, 16)         1040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 41, 1, 16)         0         \n",
      "=================================================================\n",
      "Total params: 9,392\n",
      "Trainable params: 9,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# convolutional layers\n",
    "model = tfk.Sequential()\n",
    "model.add(tfk.layers.Conv2D(filters=16, kernel_size=(1,2), input_shape=(100,40,1), strides=(1, 2)))\n",
    "model.add(tfk.layers.LeakyReLU(alpha=0.01))\n",
    "model.add(tfk.layers.Conv2D(filters=16, kernel_size=(4,1)))\n",
    "model.add(tfk.layers.Conv2D(filters=16, kernel_size=(4,1)))\n",
    "model.add(tfk.layers.Conv2D(filters=16, kernel_size=(1,2), strides=(1, 2)))\n",
    "model.add(tfk.layers.LeakyReLU(alpha=0.01))\n",
    "model.add(tfk.layers.Conv2D(filters=16, kernel_size=(4,1)))\n",
    "model.add(tfk.layers.Conv2D(filters=16, kernel_size=(4,1)))\n",
    "model.add(tfk.layers.Conv2D(filters=16, kernel_size=(1,10), input_shape=(100,10,1)))\n",
    "model.add(tfk.layers.Conv2D(filters=16, kernel_size=(4,1)))\n",
    "model.add(tfk.layers.Conv2D(filters=16, kernel_size=(4,1)))\n",
    "model.add(tfk.layers.MaxPooling2D(pool_size=(2,1)))\n",
    "# model.add(tfk.layers.TimeDistributed(tfk.layers.Flatten()))\n",
    "\n",
    "# lstm layer\n",
    "# model.add(tfk.layers.LSTM(64))\n",
    "# model.add(tfk.layers.Dense(3,activation='softmax'))\n",
    "\n",
    "# # compile model and summarize\n",
    "# adam = tfk.optimizers.Adam(lr=0.01, epsilon=1)\n",
    "# model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5325 samples, validate on 1332 samples\n",
      "Epoch 1/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4430 - acc: 0.8597 - val_loss: 0.3421 - val_acc: 0.9032\n",
      "Epoch 2/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4425 - acc: 0.8601 - val_loss: 0.3450 - val_acc: 0.9032\n",
      "Epoch 3/40\n",
      "5325/5325 [==============================] - 13s 2ms/sample - loss: 0.4398 - acc: 0.8605 - val_loss: 0.3374 - val_acc: 0.9032\n",
      "Epoch 4/40\n",
      "5325/5325 [==============================] - 13s 2ms/sample - loss: 0.4368 - acc: 0.8584 - val_loss: 0.3407 - val_acc: 0.9032\n",
      "Epoch 5/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4361 - acc: 0.8607 - val_loss: 0.3352 - val_acc: 0.9032\n",
      "Epoch 6/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4318 - acc: 0.8597 - val_loss: 0.3430 - val_acc: 0.9032\n",
      "Epoch 7/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4317 - acc: 0.8588 - val_loss: 0.3450 - val_acc: 0.9032\n",
      "Epoch 8/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4289 - acc: 0.8590 - val_loss: 0.3390 - val_acc: 0.9032\n",
      "Epoch 9/40\n",
      "5325/5325 [==============================] - 13s 2ms/sample - loss: 0.4281 - acc: 0.8586 - val_loss: 0.3349 - val_acc: 0.9032\n",
      "Epoch 10/40\n",
      "5325/5325 [==============================] - 13s 2ms/sample - loss: 0.4282 - acc: 0.8593 - val_loss: 0.3419 - val_acc: 0.9032\n",
      "Epoch 11/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4255 - acc: 0.8584 - val_loss: 0.3567 - val_acc: 0.9017\n",
      "Epoch 12/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4250 - acc: 0.8592 - val_loss: 0.3501 - val_acc: 0.9032\n",
      "Epoch 13/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4228 - acc: 0.8592 - val_loss: 0.3417 - val_acc: 0.9024\n",
      "Epoch 14/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4188 - acc: 0.8595 - val_loss: 0.3345 - val_acc: 0.9032\n",
      "Epoch 15/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4188 - acc: 0.8595 - val_loss: 0.3392 - val_acc: 0.9024\n",
      "Epoch 16/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4172 - acc: 0.8599 - val_loss: 0.3618 - val_acc: 0.9002\n",
      "Epoch 17/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4168 - acc: 0.8586 - val_loss: 0.3584 - val_acc: 0.9017\n",
      "Epoch 18/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4163 - acc: 0.8593 - val_loss: 0.3410 - val_acc: 0.9024\n",
      "Epoch 19/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4131 - acc: 0.8597 - val_loss: 0.3766 - val_acc: 0.8964\n",
      "Epoch 20/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4144 - acc: 0.8607 - val_loss: 0.3617 - val_acc: 0.9009\n",
      "Epoch 21/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4122 - acc: 0.8601 - val_loss: 0.3384 - val_acc: 0.9032\n",
      "Epoch 22/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4120 - acc: 0.8592 - val_loss: 0.3561 - val_acc: 0.9002\n",
      "Epoch 23/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4116 - acc: 0.8605 - val_loss: 0.4032 - val_acc: 0.8874\n",
      "Epoch 24/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4141 - acc: 0.8603 - val_loss: 0.3393 - val_acc: 0.9032\n",
      "Epoch 25/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4058 - acc: 0.8588 - val_loss: 0.3405 - val_acc: 0.9009\n",
      "Epoch 26/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4052 - acc: 0.8599 - val_loss: 0.3593 - val_acc: 0.8979\n",
      "Epoch 27/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4050 - acc: 0.8599 - val_loss: 0.3416 - val_acc: 0.9017\n",
      "Epoch 28/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4010 - acc: 0.8605 - val_loss: 0.3522 - val_acc: 0.9002\n",
      "Epoch 29/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4037 - acc: 0.8582 - val_loss: 0.3430 - val_acc: 0.9032\n",
      "Epoch 30/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4033 - acc: 0.8590 - val_loss: 0.3767 - val_acc: 0.8994\n",
      "Epoch 31/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4015 - acc: 0.8595 - val_loss: 0.3385 - val_acc: 0.9032\n",
      "Epoch 32/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.3992 - acc: 0.8614 - val_loss: 0.3475 - val_acc: 0.9009\n",
      "Epoch 33/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.4023 - acc: 0.8590 - val_loss: 0.3449 - val_acc: 0.9002\n",
      "Epoch 34/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.3981 - acc: 0.8599 - val_loss: 0.3442 - val_acc: 0.9032\n",
      "Epoch 35/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.3973 - acc: 0.8612 - val_loss: 0.3451 - val_acc: 0.9032\n",
      "Epoch 36/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.3953 - acc: 0.8614 - val_loss: 0.3473 - val_acc: 0.9002\n",
      "Epoch 37/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.3961 - acc: 0.8593 - val_loss: 0.3598 - val_acc: 0.9017\n",
      "Epoch 38/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.3925 - acc: 0.8612 - val_loss: 0.3790 - val_acc: 0.8964\n",
      "Epoch 39/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.3970 - acc: 0.8607 - val_loss: 0.3433 - val_acc: 0.9017\n",
      "Epoch 40/40\n",
      "5325/5325 [==============================] - 12s 2ms/sample - loss: 0.3933 - acc: 0.8601 - val_loss: 0.3432 - val_acc: 0.9009\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2219/2219 [==============================] - 2s 738us/sample - loss: 0.4583 - acc: 0.8463\n",
      "84.63271856307983\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.09      0.11       171\n",
      "           1       0.93      0.91      0.92      2043\n",
      "           2       0.01      0.20      0.02         5\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      2219\n",
      "   macro avg       0.36      0.40      0.35      2219\n",
      "weighted avg       0.87      0.85      0.86      2219\n",
      "\n",
      "[[  16   92    0]\n",
      " [ 134 1861    4]\n",
      " [  21   90    1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "target_names = ['down', 'stationary', 'up']\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "y_test_bool = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_pred_bool, y_test_bool))\n",
    "cm = confusion_matrix(y_test_bool, y_pred_bool, labels=[0,1,2])\n",
    "print(cm)\n",
    "# onehot_encoder.inverse_transform(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ebe3166f25ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b--'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'g-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['loss'],'b--',lw=2,label='train_loss')\n",
    "plt.plot(history.history['val_loss'],'g-',lw=2,label='val_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cost')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history.history['acc'],'b--',lw=2,label='train_acc')\n",
    "plt.plot(history.history['val_acc'],'g-',lw=2,label='val_acc')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
