{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.stats import zscore\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "# batch size for model\n",
    "BATCH_SIZE = 100\n",
    "# number of epochs\n",
    "EPOCHS = 20\n",
    "# proportion of validation data\n",
    "VALIDATION_SPLIT = 0.2\n",
    "# learning rate and epsilon for ADAM optimizer\n",
    "LEARNING_RATE = 0.01\n",
    "EPSILON = 1\n",
    "# path where data is stored\n",
    "PATH=\"/Users/tanvipotdar/Projects/thesis/data/INTC_2015-01-01_2015-01-31_10\"\n",
    "# prediction horizon\n",
    "K = 50 \n",
    "# threshold to decide which category midprice direction falls in (up, down, stationary)\n",
    "ALPHA = 0.001\n",
    "\n",
    "# Static objects\n",
    "# instantiate one hot encoder here so that all classes will always map to the same labels\n",
    "onehot_encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ask_price_1</th>\n",
       "      <th>ask_size_1</th>\n",
       "      <th>bid_price_1</th>\n",
       "      <th>bid_size_1</th>\n",
       "      <th>ask_price_2</th>\n",
       "      <th>ask_size_2</th>\n",
       "      <th>bid_price_2</th>\n",
       "      <th>bid_size_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>367300</td>\n",
       "      <td>4000</td>\n",
       "      <td>365200</td>\n",
       "      <td>400</td>\n",
       "      <td>367500</td>\n",
       "      <td>200</td>\n",
       "      <td>364800</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>367300</td>\n",
       "      <td>4000</td>\n",
       "      <td>365200</td>\n",
       "      <td>400</td>\n",
       "      <td>367500</td>\n",
       "      <td>200</td>\n",
       "      <td>364800</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367300</td>\n",
       "      <td>4000</td>\n",
       "      <td>365200</td>\n",
       "      <td>100</td>\n",
       "      <td>367500</td>\n",
       "      <td>200</td>\n",
       "      <td>364800</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>367300</td>\n",
       "      <td>4000</td>\n",
       "      <td>365200</td>\n",
       "      <td>100</td>\n",
       "      <td>367500</td>\n",
       "      <td>200</td>\n",
       "      <td>364800</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367300</td>\n",
       "      <td>4000</td>\n",
       "      <td>365200</td>\n",
       "      <td>100</td>\n",
       "      <td>367500</td>\n",
       "      <td>200</td>\n",
       "      <td>364800</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ask_price_1  ask_size_1  bid_price_1  bid_size_1  ask_price_2  ask_size_2  \\\n",
       "0       367300        4000       365200         400       367500         200   \n",
       "1       367300        4000       365200         400       367500         200   \n",
       "2       367300        4000       365200         100       367500         200   \n",
       "3       367300        4000       365200         100       367500         200   \n",
       "4       367300        4000       365200         100       367500         200   \n",
       "\n",
       "   bid_price_2  bid_size_2  \n",
       "0       364800         300  \n",
       "1       364800         300  \n",
       "2       364800         300  \n",
       "3       364800         300  \n",
       "4       364800         300  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data(path, num_files_to_choose=np.inf):\n",
    "    all_files = glob.glob(path + \"/*orderbook_10.csv\")\n",
    "    all_files.sort()\n",
    "    i = min(num_files_to_choose, len(all_files))\n",
    "    orderbooks = []\n",
    "    for filename in all_files[:i]:\n",
    "        df = pd.read_csv(filename, index_col=None, header=None, usecols=list(range(8)))\n",
    "        orderbooks.append(df)\n",
    "    orderbook = pd.concat(orderbooks, axis=0, ignore_index=True)\n",
    "    col_names = ['ask_price_', 'ask_size_', 'bid_price_', 'bid_size_']\n",
    "    nums = map(str, range(1,3))\n",
    "    orderbook.columns = [y + x for x in nums for y in col_names]\n",
    "    return orderbook\n",
    "data = get_data(path=PATH, num_files_to_choose=3)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ask_price_1</th>\n",
       "      <th>ask_size_1</th>\n",
       "      <th>bid_price_1</th>\n",
       "      <th>bid_size_1</th>\n",
       "      <th>ask_price_2</th>\n",
       "      <th>ask_size_2</th>\n",
       "      <th>bid_price_2</th>\n",
       "      <th>bid_size_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.641743</td>\n",
       "      <td>-0.076267</td>\n",
       "      <td>1.171577</td>\n",
       "      <td>-0.753204</td>\n",
       "      <td>1.665477</td>\n",
       "      <td>-1.888278</td>\n",
       "      <td>1.100263</td>\n",
       "      <td>-0.914844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.641743</td>\n",
       "      <td>-0.076267</td>\n",
       "      <td>1.171577</td>\n",
       "      <td>-0.753204</td>\n",
       "      <td>1.665477</td>\n",
       "      <td>-1.888278</td>\n",
       "      <td>1.100263</td>\n",
       "      <td>-0.914844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.641743</td>\n",
       "      <td>-0.076267</td>\n",
       "      <td>1.171577</td>\n",
       "      <td>-0.813901</td>\n",
       "      <td>1.665477</td>\n",
       "      <td>-1.888278</td>\n",
       "      <td>1.100263</td>\n",
       "      <td>-0.914844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.641743</td>\n",
       "      <td>-0.076267</td>\n",
       "      <td>1.171577</td>\n",
       "      <td>-0.813901</td>\n",
       "      <td>1.665477</td>\n",
       "      <td>-1.888278</td>\n",
       "      <td>1.100263</td>\n",
       "      <td>-0.914844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.641743</td>\n",
       "      <td>-0.076267</td>\n",
       "      <td>1.171577</td>\n",
       "      <td>-0.813901</td>\n",
       "      <td>1.665477</td>\n",
       "      <td>-1.888278</td>\n",
       "      <td>1.100263</td>\n",
       "      <td>-0.914844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ask_price_1  ask_size_1  bid_price_1  bid_size_1  ask_price_2  ask_size_2  \\\n",
       "0     1.641743   -0.076267     1.171577   -0.753204     1.665477   -1.888278   \n",
       "1     1.641743   -0.076267     1.171577   -0.753204     1.665477   -1.888278   \n",
       "2     1.641743   -0.076267     1.171577   -0.813901     1.665477   -1.888278   \n",
       "3     1.641743   -0.076267     1.171577   -0.813901     1.665477   -1.888278   \n",
       "4     1.641743   -0.076267     1.171577   -0.813901     1.665477   -1.888278   \n",
       "\n",
       "   bid_price_2  bid_size_2  \n",
       "0     1.100263   -0.914844  \n",
       "1     1.100263   -0.914844  \n",
       "2     1.100263   -0.914844  \n",
       "3     1.100263   -0.914844  \n",
       "4     1.100263   -0.914844  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalise_data(data):\n",
    "    normalised_data = data.apply(zscore)\n",
    "    return normalised_data\n",
    "normalised_data = normalise_data(data)\n",
    "normalised_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothed labelling of the midprice/ K is the prediction horizon\n",
    "def smooth_midprice_using_k_lookahead(normalised_data, k):\n",
    "    normalised_data['midprice'] = (normalised_data.ask_price_1+normalised_data.bid_price_1)/2\n",
    "    # mean of previous k mid-prices\n",
    "    normalised_data['m_minus'] = normalised_data['midprice'].rolling(window=k).mean()\n",
    "    # mean of next k mid-prices\n",
    "    normalised_data['m_plus'] = normalised_data['midprice'][::-1].rolling(window=k).mean()[::-1]\n",
    "    return normalised_data\n",
    "normalised_data = smooth_midprice_using_k_lookahead(normalised_data, k=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label the smoothed mid-prices based on a threshold/ ALPHA is the threshold \n",
    "def create_midprice_labels(normalised_data):\n",
    "    normalised_data['change'] = (normalised_data.m_plus - normalised_data.m_minus)/normalised_data.m_minus\n",
    "    # assign categories up, down, stationary\n",
    "    normalised_data['label'] = pd.cut(normalised_data.change, bins=[-np.inf, -ALPHA, ALPHA, np.inf], \n",
    "                                    labels=['down', 'stationary', 'up'])\n",
    "    # drop all unlabelled values (will be first and last k values as they have no m_minus/m_plus value)\n",
    "    normalised_data.dropna(inplace=True)\n",
    "    return normalised_data\n",
    "normalised_data = create_midprice_labels(normalised_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 39897000 into shape (30690,100,8,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0e69787417aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_and_categorise_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalised_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training input shape:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test input shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0e69787417aa>\u001b[0m in \u001b[0;36mreshape_and_categorise_data\u001b[0;34m(normalised_data, n)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0minput_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 39897000 into shape (30690,100,8,1)"
     ]
    }
   ],
   "source": [
    "# split into train and test data\n",
    "N = len(normalised_data) - len(normalised_data)%100\n",
    "def reshape_and_categorise_data(normalised_data, n):\n",
    "    data = normalised_data[:n]\n",
    "    cols = data.columns.to_list()[:8]\n",
    "    input_data = data[cols]\n",
    "    input_array = input_data.to_numpy().reshape(n//100,100,8,1)\n",
    "\n",
    "    output_data = data.label.to_numpy()[::-100][::-1]\n",
    "    integer_encoded = output_data.reshape(len(output_data), 1)\n",
    "    output_array = onehot_encoder.fit_transform(integer_encoded)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_array, output_array, shuffle=False)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = reshape_and_categorise_data(normalised_data, N)\n",
    "print(\"Training input shape:\",X_train.shape)\n",
    "print(\"Test input shape:\", X_test.shape)\n",
    "print(\"Training output shape:\", y_train.shape)\n",
    "print(\"Test input shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This OneHotEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-66443bdb4b59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mapping of labels to one hot encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Using np.argmax equates: 0-down, 1-stationary, 2-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenvs/lob/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;31m#     raise ValueError(\"only supported for categorical features\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'categories_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenvs/lob/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This OneHotEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "# mapping of labels to one hot encoding\n",
    "encodings = [[1,0,0],[0,0,1],[0,1,0]]\n",
    "classes = onehot_encoder.inverse_transform(encodings)\n",
    "print(zip(classes, encodings))\n",
    "# Using np.argmax equates: 0-down, 1-stationary, 2-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 100, 20, 16)       48        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 100, 20, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 97, 20, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 94, 20, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 94, 10, 16)        528       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 94, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 91, 10, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 88, 10, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 88, 1, 16)         2576      \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 85, 1, 32)         2080      \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 82, 1, 32)         4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 27, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 27, 32)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 100)               13300     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 27,123\n",
      "Trainable params: 27,123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    # convolutional layers\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=16, kernel_size=(1,2), input_shape=(100,40,1), strides=(1, 2)))\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.01))\n",
    "    model.add(keras.layers.Conv2D(filters=16, kernel_size=(4,1)))\n",
    "    model.add(keras.layers.Conv2D(filters=16, kernel_size=(4,1)))\n",
    "    model.add(keras.layers.Conv2D(filters=16, kernel_size=(1,2), strides=(1, 2)))\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.01))\n",
    "    model.add(keras.layers.Conv2D(filters=16, kernel_size=(4,1)))\n",
    "    model.add(keras.layers.Conv2D(filters=16, kernel_size=(4,1)))\n",
    "    model.add(keras.layers.Conv2D(filters=16, kernel_size=(1,10), input_shape=(100,10,1)))\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=(4,1)))\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=(4,1)))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(3,1)))\n",
    "    model.add(keras.layers.TimeDistributed(keras.layers.Flatten()))\n",
    "\n",
    "    # lstm layer\n",
    "    model.add(keras.layers.LSTM(100))\n",
    "    model.add(keras.layers.Dense(3,activation='softmax'))\n",
    "    # compile model and summarize\n",
    "    adam = keras.optimizers.Adam(lr=LEARNING_RATE, epsilon=1)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18413 samples, validate on 4604 samples\n",
      "WARNING:tensorflow:From /Users/tanvipotdar/pyenvs/lob/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "10000/18413 [===============>..............] - ETA: 23s - loss: 1.1108 - acc: 0.3990"
     ]
    }
   ],
   "source": [
    "def fit_and_evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VALIDATION_SPLIT)\n",
    "    score, accuracy = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "    print(\"Accuracy is {}%\".format(accuracy*100))\n",
    "    return accuracy*100, history\n",
    "accuracy, history = fit_and_evaluate_model(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(history):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(history.history['loss'],'b--',lw=2,label='train_loss')\n",
    "    plt.plot(history.history['val_loss'],'g-',lw=2,label='val_loss')\n",
    "    plt.legend()\n",
    "    # plt.ylim([.5,1.3])\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(history.history['acc'],'b--',lw=2,label='train_acc')\n",
    "    plt.plot(history.history['val_acc'],'g-',lw=2,label='val_acc')\n",
    "    plt.legend()\n",
    "    # plt.ylim([.2,1.0])\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "plots(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report(model, X_test, y_test, X_train, y_train):\n",
    "    target_names = ['down', 'stationary', 'up']\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "    y_test_bool = np.argmax(y_test, axis=1)\n",
    "    print(classification_report(y_pred_bool, y_test_bool, target_names=target_names))\n",
    "    print(confusion_matrix(y_test_bool, y_pred_bool, labels=[0,1,2]))\n",
    "get_report(model, X_test, y_test, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
