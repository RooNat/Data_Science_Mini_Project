{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The .ipynb file for processing the data in HSBC_Set01 folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Fnmatch:*** https://linuxhint.com/fnmatch-module-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import fnmatch #to find the files which match a pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Reference:*** \n",
    "\n",
    "https://www.tutorialspoint.com/python-read-all-csv-files-in-a-folder-in-pandas\n",
    "\n",
    "https://www.w3schools.com/python/ref_func_zip.asp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert a list to dictionary\n",
    "def Convert(a):\n",
    "    it = iter(a) # returns an iterator for the given list.\n",
    "    res_dct = dict(zip(it, it)) \n",
    "    return res_dct\n",
    "\n",
    "# Based on the value of 'bid' and 'ask', \n",
    "# assign the corresponding value to the column 'State' \n",
    "def check_state(bid,ask):\n",
    "    if bid==1 and ask==0:\n",
    "        return 'bid'\n",
    "    elif bid==0 and ask==1:\n",
    "        return 'ask'\n",
    "    elif bid==1 and ask==1:\n",
    "        return 'bid/ask'\n",
    "    else:\n",
    "        return 'Nan'\n",
    "\n",
    "\n",
    "# Pass the merged dataframe and the origin LOB dataframe to the function\n",
    "# For each time point, match a corresponding state(bid or ask) with it\n",
    "# 'result' is the Tapes dataframe, 'df' is the LOBs dataframe\n",
    "def Match_bid_ask(result,df):\n",
    "    # get every row of the dataframe, get the index and each data point\n",
    "    for index, rows in result.iterrows():\n",
    "        bid_in=0\n",
    "        ask_in=0\n",
    "\n",
    "        # make the Price and Qty be paired together\n",
    "        match_array=np.array([rows.Price,rows.Qty])\n",
    "        bid_array=np.array(rows.bid)\n",
    "        ask_array=np.array(rows.ask)\n",
    "        for i in bid_array:\n",
    "            # check whether the matched array is completely equal to any array in the bid feature.\n",
    "            if np.array_equal(match_array,i):\n",
    "                bid_in=1\n",
    "                break\n",
    "            # check whether the bid array includes the same price which corresponds to the Price\n",
    "            elif rows.Price==i[0]:\n",
    "                # get the index of corresponding \"Time\" feature in LOBs dataframe\n",
    "                index_df=df[df['Time']==rows.Time].index.values\n",
    "\n",
    "                # Scan the next line of the current line in LOBs dataframe\n",
    "                # get the data of \"bid\" feature\n",
    "                df_bid=df.loc[index_df[0]+1][\"bid\"]\n",
    "\n",
    "                # check whether the bid array includes the same price \n",
    "                # which corresponds to the Price in the current row\n",
    "                if np.any(np.isin(df_bid,rows.Price)):\n",
    "                    # scan each data point in the bid array\n",
    "                    for k in df_bid:\n",
    "                        # Under the same price, check whether the quantity decreases\n",
    "                        if k[0]==i[0] and k[1]<i[1]:\n",
    "                            # if it decreases at the next time point,\n",
    "                            # means that there is a deal at the current time\n",
    "                            # let the value of \"bid_in\" be 1, means the type of deal is \"bid\"\n",
    "                            bid_in=1\n",
    "                            break\n",
    "                else:\n",
    "                    bid_in=1\n",
    "                    break\n",
    "        # Do the same thing to \"ask\" feature as the \"bid\" feature above\n",
    "        for j in ask_array:\n",
    "            if np.array_equal(match_array,j):\n",
    "                ask_in=1\n",
    "                break\n",
    "            elif rows.Price==j[0]:\n",
    "                index_df=df[df['Time']==rows.Time].index.values\n",
    "                df_ask=df.loc[index_df[0]+1][\"ask\"]\n",
    "                if np.any(np.isin(df_ask,rows.Price)):\n",
    "                    for k in df_ask:\n",
    "                        if k[0]==j[0] and k[1]<j[1]:\n",
    "                            ask_in=1\n",
    "                            break\n",
    "                else:\n",
    "                    ask_in=1\n",
    "                    break\n",
    "    # Assign the type of deal(\"bid\" or \"ask\") to the column of \"State\"\n",
    "    result.at[index,'State']=check_state(bid_in,ask_in)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Pass the LOB data(.txt file) and Tapes data(.csv file) to the function\n",
    "# Tidy up the data and find the corresponding state for each time point in Tapes data\n",
    "def data_wrangling(LOBs_data,Tapes_data):\n",
    "    # list to array\n",
    "    New_data=[]\n",
    "    test_lines=np.asarray(LOBs_data,dtype=object)\n",
    "\n",
    "    # Normalize each row of LOBs data to join with Tapes data\n",
    "    # The format should be [[\"Time\", 5.673],[\"Encode\", \"Exch0\"],[\"bid\",[]],[\"ask\",[]]]\n",
    "    for i in test_lines:\n",
    "        every_line=[[\"Time\",i[0]],[\"Encode\",i[1]],i[2][0],i[2][1]]\n",
    "        New_data.append(every_line)\n",
    "\n",
    "    # Convert every list in the data to dictionary\n",
    "    # E.g. [\"Time\", 5.673] to {\"Time\": 5.673}\n",
    "    for i in New_data:\n",
    "        i[0]=Convert(i[0])\n",
    "        i[1]=Convert(i[1])\n",
    "        i[2]=Convert(i[2])\n",
    "        i[3]=Convert(i[3])\n",
    "        # Merge the dictionaries\n",
    "        # {\"Time\":5.673, \"Encode\": \"Exch0\", \"bid\": [], \"ask\": []}\n",
    "        i[0]=i[0]|i[1]|i[2]|i[3] \n",
    "\n",
    "    # delete the redundant keys and values\n",
    "    New_data=np.delete(New_data,[1,2,3],1)\n",
    "    data_test=New_data.flatten()\n",
    "    #Convert the array to list\n",
    "    data_test2=data_test.tolist()\n",
    "\n",
    "    # Convert the precessed LOBs data to dataframe\n",
    "    df=pd.DataFrame(data_test2)\n",
    "\n",
    "    # join the Tapes data with LoBs data in the form of \"inner\".\n",
    "    # The common key is \"Time\"\n",
    "    merge_table = pd.merge(Tapes_data,df, on='Time', how=\"inner\")\n",
    "\n",
    "    # Based on the features \"Time\",\"bid\",\"ask\", \n",
    "    # to find the State for each time point \n",
    "    result=Match_bid_ask(merge_table,df)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columns_name=['Time','Price','Qty']\n",
    "# Read all .csv file in Tapes folder\n",
    "# get the name of .csv file\n",
    "\n",
    "folder_path = \"./Dataset/HSBC_Set01/Tapes/\"\n",
    "new_folder_path=\"./Processed_data/\"\n",
    "# define the prefix for the new file names\n",
    "prefix = \"New_\"\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # read the csv file\n",
    "        Tapedata = pd.read_csv(os.path.join(folder_path, filename),names=columns_name,header=None)\n",
    "        \n",
    "        # add a feature/column called \"State\"\n",
    "        Tapedata[\"State\"]=\" \"\n",
    "\n",
    "        # get the name of filename excluding the suffix .csv\n",
    "        name=os.path.splitext(filename)[0]\n",
    "\n",
    "        # a pattern to get the date embedded in the filename\n",
    "        pattern = r\"\\d{4}-\\d{2}-\\d{2}\"\n",
    "        match=re.search(pattern,name)\n",
    "        if match:\n",
    "            # print the matched date string\n",
    "            Date_match=match.group(0)\n",
    "            # read the single file\n",
    "            LOBs_folder_path=r'C:\\Users\\hp\\Documents\\DS_miniproject\\HSBC_Set01\\LOBS'\n",
    "            LOB_file=\"\"\n",
    "\n",
    "            # Based on the date, \n",
    "            # find .txt file whose filename has the same date as .csv file\n",
    "            for file in os.listdir(LOBs_folder_path):\n",
    "                if fnmatch.fnmatch(file, f'*{Date_match}*') and file.endswith(\".txt\"):\n",
    "                    LOB_file=file\n",
    "                    break\n",
    "\n",
    "            # Convert Exch0 to the type \"String\"\n",
    "            substring=\"Exch0\"\n",
    "            LOBdata=[]\n",
    "            with open(os.path.join(LOBs_folder_path, LOB_file),'r') as f:\n",
    "                for line in f:\n",
    "                    # add quotation marks around the substring using an f-string\n",
    "                    new_line = line.replace(substring, f'\"{substring}\"')\n",
    "\n",
    "                    # remove the quotation marks around the line\n",
    "                    # Convert the string to the list\n",
    "                    LOBdata.append(eval(new_line.strip('\\n')))\n",
    "            \n",
    "            # Process the data\n",
    "            Result=data_wrangling(LOBdata,Tapedata)\n",
    "\n",
    "            # write the new data to the new file\n",
    "            # save the file to 'Processed_data' folder\n",
    "            new_filename=prefix+name+\".csv\"\n",
    "            Result.to_csv(os.path.join(new_folder_path, new_filename), index=False)\n",
    "\n",
    "        else:\n",
    "            print(\"No match found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Obtain stock data\n",
    "df = pd.read_csv('./Dataset/HSBC_Set01/Tapes/.csv')\n",
    "\n",
    "# Step 2: Load data into a pandas DataFrame\n",
    "\n",
    "# Step 3: Convert the date column to a datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Step 4: Set the date column as the index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Step 5: Create a time series plot\n",
    "df['Close'].plot()\n",
    "plt.title('Stock Status')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.scatter(BID[:, 0], BID[:, 1], c='green', alpha=0.6, edgecolors='black', label='BID', s=60)\n",
    "plt.scatter(ASK[:, 0], ASK[:, 1], c='red', alpha=0.6, edgecolors='black', label='ASK', s=60)\n",
    "plt.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(221)\n",
    "plt.plot(df.Close, '-', label='By Days')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Stock market prices are highly unpredictable and volatile. This means that there are no consistent patterns in the data that allwows us to model stock prices over time perfectly. However, we can model the data, so that the predictions we make can somehow correlate with the actual behavior of the data. We try to do that with Long-Term Short Memory (LSTM) models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import urllib.request, json\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "data_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "531a32d43b6b4a72574c344c8d9a7972976cda1ae5ac9990fb3d5918c7e19967"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}